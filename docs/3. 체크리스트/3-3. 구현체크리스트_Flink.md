# Flink 최적화 스트림 처리 구현 체크리스트

> **🎯 핵심 목표**: **역할 분담 최적화** - 복잡한 작업만 Flink, 간단한 작업은 Worker  
> **💡 아키텍처**: Flink 4개 Statement (JOIN/WINDOW 전용) + Worker (단순 처리)

---

## 📊 **최적화된 역할 분담**

### **🔥 Flink 담당 (복잡한 작업)**
- **RTB 재계산**: Campaign JOIN + 알고리즘 계산 + Redis 캐시
- **성과 집계**: 5분 WINDOW + CTR/CVR 계산  
- **전환 매칭**: 24시간 WINDOW + 클릭-전환 JOIN
- **중복 탐지**: 5분 WINDOW + 중복 클릭 탐지 + 보상 이벤트 발행 ⭐ 신규

### **⚡ Worker 담당 (간단한 작업)**
- **잔액 차감**: 클릭 이벤트 → DB INSERT (실시간, 중복 체크 없음)
- **예산 모니터링**: Redis 카운터 업데이트 (실시간)
- **캠페인 상태**: 예산 소진 시 상태 변경 (배치)
- **보상 처리**: compensation-events → DB 잔액 복구 ⭐ 신규

---

## 🚀 Flink Statement 구성 (4개)

### **✅ Statement 1: RTB_CACHE_UPDATER**

```sql
-- 🎯 RTB 순위 계산 및 Redis 캐시 업데이트 (복잡한 JOIN + 알고리즘)

CREATE TABLE campaign_events_source (
  event_type STRING,
  timestamp_field TIMESTAMP(3),
  campaign_id BIGINT,
  advertiser_id BIGINT, 
  product_id BIGINT,
  placement STRING,
  category STRING,
  bid_price DECIMAL(10,2),
  status STRING,
  WATERMARK FOR timestamp_field AS timestamp_field - INTERVAL '30' SECOND
) WITH (
  'connector' = 'kafka',
  'topic' = 'campaign-events',
  'properties.bootstrap.servers' = '${KAFKA_BROKERS}',
  'properties.group.id' = 'flink-rtb-processor',
  'format' = 'json'
);

-- 🎯 RTB 점수 계산 및 순위 캐시 생성
-- 목적: 캠페인 변경 시 실시간으로 RTB 순위를 재계산하여 Redis에 저장
INSERT INTO rtb_ranking_cache
SELECT 
  placement,                    -- 광고 영역 (HOME, CATEGORY, SEARCH 등)
  category,                     -- 상품 카테고리 (electronics, fashion 등)
  
  -- 📊 RTB 순위 리스트 생성 (점수순 정렬)
  COLLECT(
    ROW(
      product_id,               -- 광고 상품 ID
      -- 🧮 S_α 점수 계산: 입찰가 × CTR + α × CTR × CVR × 상품가격 
      -- α=0.1: 전환율 가중치, CTR/CVR 기본값으로 방어로직 적용
      bid_price * COALESCE(pm.ctr, 0.01) + 0.1 * COALESCE(pm.ctr, 0.01) * COALESCE(pm.cvr, 0.005) * pmd.product_price,
      bid_price,                -- 원본 입찰가
      campaign_id,              -- 캠페인 ID
      advertiser_id             -- 광고주 ID
    ) 
    -- 📈 점수 내림차순 정렬 (높은 점수 = 상위 노출)
    ORDER BY (bid_price * COALESCE(pm.ctr, 0.01) + 0.1 * COALESCE(pm.ctr, 0.01) * COALESCE(pm.cvr, 0.005) * pmd.product_price) DESC
  ) as ranking_list,
  
  COUNT(*) as total_campaigns,  -- 해당 영역의 총 경쟁 캠페인 수
  CURRENT_TIMESTAMP as updated_at

FROM campaign_events_source c
-- 🎭 성과 데이터 조인 (CTR/CVR 가져오기, 없으면 방어로직 적용)
LEFT JOIN product_metrics_cache pm ON c.product_id = pm.product_id
-- 💰 상품 메타데이터 조인 (상품 가격 정보)
LEFT JOIN product_meta_data pmd ON c.product_id = pmd.product_id

WHERE c.event_type IN ('CAMPAIGN_CREATE', 'CAMPAIGN_UPDATE', 'CAMPAIGN_ACTIVATE')
  AND c.status = 'ACTIVE'      -- 활성 캠페인만 RTB 경쟁 참여
GROUP BY c.placement, c.category;
```

### **✅ Statement 2: PERFORMANCE_AGGREGATOR**

```sql
-- 📊 실시간 성과 집계 (5분 WINDOW + 복잡한 집계)

CREATE TABLE ad_events_source (
  event_type STRING,
  timestamp_field TIMESTAMP(3),
  campaign_id BIGINT,
  advertiser_id BIGINT,
  product_id BIGINT,
  placement STRING,
  category STRING,
  actual_price DECIMAL(10,2),
  revenue_amount DECIMAL(15,2),
  WATERMARK FOR timestamp_field AS timestamp_field - INTERVAL '10' SECOND
) WITH (
  'connector' = 'kafka',
  'topic' = 'ad-events',
  'properties.bootstrap.servers' = '${KAFKA_BROKERS}',
  'properties.group.id' = 'flink-performance-processor',
  'format' = 'json'
);

-- 📊 5분 윈도우 성과 집계
-- 목적: 실시간으로 광고 성과를 집계하여 CTR/CVR 등을 계산하고 Redis에 저장
INSERT INTO ad_performance_metrics_realtime
SELECT 
  ROW_NUMBER() OVER (ORDER BY window_start) as id,
  campaign_id,                  -- 캠페인 ID
  product_id,                   -- 상품 ID
  placement,                    -- 광고 영역
  DATE_FORMAT(window_start, 'yyyy-MM-dd HH:mm:ss') as metric_time,
  
  -- 📈 기본 지표 카운팅
  SUM(CASE WHEN event_type = 'IMPRESSION' THEN 1 ELSE 0 END) as impression_count, -- 노출 수
  SUM(CASE WHEN event_type = 'CLICK' THEN 1 ELSE 0 END) as click_count,           -- 클릭 수
  SUM(CASE WHEN event_type = 'CONVERSION' THEN 1 ELSE 0 END) as conversion_count, -- 전환 수
  
  -- 💰 비용/수익 집계
  SUM(CASE WHEN event_type = 'CLICK' THEN actual_price ELSE 0 END) as total_spend,    -- 총 광고비
  SUM(CASE WHEN event_type = 'CONVERSION' THEN revenue_amount ELSE 0 END) as total_revenue, -- 총 매출
  
  -- 🧮 성과 지표 계산 (0으로 나누기 방지)
  -- CTR (Click Through Rate): 클릭률 = (클릭 수 / 노출 수) × 100
  CASE 
    WHEN SUM(CASE WHEN event_type = 'IMPRESSION' THEN 1 ELSE 0 END) > 0
    THEN CAST(SUM(CASE WHEN event_type = 'CLICK' THEN 1 ELSE 0 END) AS DOUBLE) 
         / SUM(CASE WHEN event_type = 'IMPRESSION' THEN 1 ELSE 0 END) * 100
    ELSE 0 
  END as ctr,
  
  -- CVR (Conversion Rate): 전환율 = (전환 수 / 클릭 수) × 100
  CASE 
    WHEN SUM(CASE WHEN event_type = 'CLICK' THEN 1 ELSE 0 END) > 0
    THEN CAST(SUM(CASE WHEN event_type = 'CONVERSION' THEN 1 ELSE 0 END) AS DOUBLE) 
         / SUM(CASE WHEN event_type = 'CLICK' THEN 1 ELSE 0 END) * 100
    ELSE 0 
  END as cvr,
  
  -- ROAS (Return on Ad Spend): 광고 수익률 = 총 매출 / 총 광고비
  CASE 
    WHEN SUM(CASE WHEN event_type = 'CLICK' THEN actual_price ELSE 0 END) > 0
    THEN SUM(CASE WHEN event_type = 'CONVERSION' THEN revenue_amount ELSE 0 END) 
         / SUM(CASE WHEN event_type = 'CLICK' THEN actual_price ELSE 0 END)
    ELSE 0 
  END as roas,
  
  CURRENT_TIMESTAMP as updated_at

FROM TABLE(
  -- ⏰ 5분 텀블링 윈도우 (5분마다 집계)
  TUMBLE(TABLE ad_events_source, DESCRIPTOR(timestamp_field), INTERVAL '5' MINUTE)
)
WHERE campaign_id IS NOT NULL    -- 유효한 캠페인만 집계
GROUP BY campaign_id, product_id, placement, window_start;
```

### **✅ Statement 3: CONVERSION_MATCHER**

```sql
-- 🔗 24시간 클릭-전환 매칭 (복잡한 WINDOW + JOIN)

CREATE TABLE order_completed_source (
  user_id BIGINT,
  mobile_device_id STRING,
  order_id BIGINT,
  timestamp_field TIMESTAMP(3),
  WATERMARK FOR timestamp_field AS timestamp_field - INTERVAL '1' HOUR
) WITH (
  'connector' = 'kafka',
  'topic' = 'order.completed',
  'properties.bootstrap.servers' = '${KAFKA_BROKERS}',
  'properties.group.id' = 'flink-conversion-processor',
  'format' = 'json'
);

-- 🔗 24시간 윈도우 클릭-전환 매칭
-- 목적: 광고 클릭과 주문 완료를 24시간 내에서 매칭하여 전환 성과 측정
INSERT INTO conversion_attribution_results
SELECT 
  click_events.ad_id,               -- 클릭된 광고 ID
  click_events.campaign_id,         -- 캠페인 ID
  click_events.advertiser_id,       -- 광고주 ID
  click_events.product_id,          -- 상품 ID
  ord.order_id,                     -- 매칭된 주문 ID
  0 as revenue_amount,              -- 💡 order.completed에는 revenue 정보 없음 (별도 조회 필요)
  TIMESTAMPDIFF(SECOND, click_events.click_time, ord.timestamp_field) as time_to_conversion, -- 클릭-전환 시간차
  'LAST_CLICK' as attribution_model, -- 어트리뷰션 모델: 마지막 클릭 기여
  click_events.click_time,          -- 클릭 발생 시간
  ord.timestamp_field as conversion_time, -- 전환(주문) 발생 시간
  CURRENT_TIMESTAMP as processed_at

FROM (
  -- 📱 클릭 이벤트 24시간 호핑 윈도우
  -- 목적: 각 디바이스별 상품별로 가장 최근 클릭을 찾기
  SELECT 
    ad_id,                          -- 광고 ID
    campaign_id,                    -- 캠페인 ID
    advertiser_id,                  -- 광고주 ID
    product_id,                     -- 상품 ID
    device_id,                      -- 디바이스 ID (mobile_device_id와 매칭)
    session_id,                     -- 세션 ID
    timestamp_field as click_time,  -- 클릭 시간
    -- 🏆 Last-Click Attribution: 같은 디바이스+상품의 가장 최근 클릭 선택
    ROW_NUMBER() OVER (
      PARTITION BY device_id, product_id 
      ORDER BY timestamp_field DESC  -- 시간 내림차순 (최신 클릭 우선)
    ) as click_rank
  FROM TABLE(
    -- ⏰ 24시간 호핑 윈도우 (1시간 슬라이드, 24시간 크기)
    HOP(TABLE ad_events_source, DESCRIPTOR(timestamp_field), INTERVAL '1' HOUR, INTERVAL '24' HOUR)
  )
  WHERE event_type = 'CLICK'        -- 클릭 이벤트만 필터링
) click_events

-- 🛒 주문 완료 이벤트와 조인
INNER JOIN order_completed_source ord
  ON ord.mobile_device_id = click_events.device_id  -- 같은 디바이스 기준 매칭
  AND ord.timestamp_field BETWEEN click_events.click_time AND click_events.click_time + INTERVAL '24' HOUR  -- 24시간 윈도우

WHERE click_events.click_rank = 1   -- 가장 최근 클릭만 선택 (Last Click Attribution)
```

### **✅ Statement 4: DUPLICATE_DETECTOR ⭐ 신규**

```sql
-- 🛡️ 중복 클릭 탐지 및 보상 이벤트 발행 (5분 WINDOW + 복잡한 GROUP BY)

CREATE TABLE ad_events_duplicate_source (
  event_type STRING,
  timestamp_field TIMESTAMP(3),
  device_id STRING,
  session_id STRING,
  user_id STRING,
  ad_id STRING,
  campaign_id BIGINT,
  advertiser_id BIGINT,
  product_id BIGINT,
  actual_price DECIMAL(10,2),
  WATERMARK FOR timestamp_field AS timestamp_field - INTERVAL '30' SECOND
) WITH (
  'connector' = 'kafka',
  'topic' = 'ad-events',
  'properties.bootstrap.servers' = '${KAFKA_BROKERS}',
  'properties.group.id' = 'flink-duplicate-detector',
  'format' = 'json'
);

-- 보상 이벤트 출력 테이블
CREATE TABLE compensation_events_sink (
  timestamp_field TIMESTAMP(3),
  advertiser_id BIGINT,
  campaign_id BIGINT,
  ad_id STRING,
  device_id STRING,
  duplicate_click_count BIGINT,
  refund_amount DECIMAL(10,2),
  original_click_timestamps ARRAY<STRING>,
  detection_window STRING,
  reason STRING,
  compensation_type STRING
) WITH (
  'connector' = 'kafka',
  'topic' = 'compensation-events',
  'properties.bootstrap.servers' = '${KAFKA_BROKERS}',
  'format' = 'json'
);

-- 🛡️ 5분 윈도우 중복 클릭 탐지 및 보상 이벤트 발행
-- 목적: 같은 디바이스에서 같은 광고를 5분 내 여러 번 클릭한 경우 탐지하여 자동 보상
INSERT INTO compensation_events_sink
SELECT 
  CURRENT_TIMESTAMP as timestamp_field,  -- 보상 처리 시간
  advertiser_id,                        -- 보상받을 광고주 ID
  campaign_id,                          -- 해당 캠페인 ID
  ad_id,                                -- 중복 클릭된 광고 ID
  device_id,                            -- 중복 클릭한 디바이스 ID
  click_count as duplicate_click_count, -- 총 중복 클릭 수
  (click_count - 1) * actual_price as refund_amount, -- 🔄 보상 금액 = (중복수-1) × 클릭단가
  click_timestamps as original_click_timestamps,      -- 원본 클릭 시간 목록 (추적용)
  '5_MINUTES' as detection_window,      -- 탐지 윈도우 크기
  'DUPLICATE_CLICK_DETECTED' as reason, -- 보상 사유
  'BALANCE_REFUND' as compensation_type -- 보상 유형: 잔액 환불

FROM (
  -- 📊 5분 윈도우 내 중복 클릭 집계
  SELECT 
    advertiser_id,                      -- 광고주 ID
    campaign_id,                        -- 캠페인 ID
    ad_id,                              -- 광고 ID
    device_id,                          -- 디바이스 ID
    actual_price,                       -- 실제 과금된 클릭 단가
    COUNT(*) as click_count,            -- 해당 윈도우 내 총 클릭 수
    -- 📝 클릭 시간 목록 수집 (디버깅 및 추적용)
    COLLECT(DATE_FORMAT(timestamp_field, 'yyyy-MM-dd HH:mm:ss.SSS')) as click_timestamps,
    window_start,                       -- 윈도우 시작 시간
    window_end                          -- 윈도우 종료 시간
    
  FROM TABLE(
    -- ⏰ 5분 텀블링 윈도우 (5분마다 중복 탐지)
    TUMBLE(TABLE ad_events_duplicate_source, DESCRIPTOR(timestamp_field), INTERVAL '5' MINUTE)
  )
  WHERE event_type = 'CLICK'            -- 클릭 이벤트만 대상
    AND device_id IS NOT NULL           -- 유효한 디바이스 ID 필수
    AND ad_id IS NOT NULL               -- 유효한 광고 ID 필수
  GROUP BY 
    advertiser_id, campaign_id, ad_id, device_id, actual_price, window_start, window_end
  HAVING COUNT(*) > 1                   -- 🚨 2회 이상 클릭된 경우만 중복으로 판정
) duplicate_clicks;
```
---

## 🏗️ **최적화된 Terraform 구성**

### **✅ 단일 Flink Job (4개 Statement 통합)**

```hcl
# 🎯 Flink Compute Pool (통합 리소스)
resource "confluent_flink_compute_pool" "rtb_processor" {
  display_name = "rtb-stream-processor"
  cloud        = "AWS"
  region       = "us-west-2"
  max_cfu      = 20
  
  environment {
    id = confluent_environment.main.id
  }
}

# 📊 Statement 1: RTB 캐시 업데이터
resource "confluent_flink_statement" "rtb_cache_updater" {
  compute_pool {
    id = confluent_flink_compute_pool.rtb_processor.id
  }
  principal {
    id = confluent_service_account.flink_runner.id
  }
  
  statement = file("${path.module}/sql/rtb_cache_updater.sql")
  properties = {
    "execution.checkpointing.interval" = "30s"
    "parallelism.default" = "4"
  }
  
  rest_endpoint = confluent_flink_compute_pool.rtb_processor.rest_endpoint
  credentials {
    key    = confluent_api_key.flink_api_key.id
    secret = confluent_api_key.flink_api_key.secret
  }
}

# 📈 Statement 2: 성과 집계
resource "confluent_flink_statement" "performance_aggregator" {
  compute_pool {
    id = confluent_flink_compute_pool.rtb_processor.id
  }
  principal {
    id = confluent_service_account.flink_runner.id
  }
  
  statement = file("${path.module}/sql/performance_aggregator.sql")
  properties = {
    "execution.checkpointing.interval" = "30s"
    "parallelism.default" = "6"
  }
  
  rest_endpoint = confluent_flink_compute_pool.rtb_processor.rest_endpoint
  credentials {
    key    = confluent_api_key.flink_api_key.id
    secret = confluent_api_key.flink_api_key.secret
  }
  
  depends_on = [confluent_flink_statement.rtb_cache_updater]
}

# 🔗 Statement 3: 전환 매칭  
resource "confluent_flink_statement" "conversion_matcher" {
  compute_pool {
    id = confluent_flink_compute_pool.rtb_processor.id
  }
  principal {
    id = confluent_service_account.flink_runner.id
  }
  
  statement = file("${path.module}/sql/conversion_matcher.sql")
  properties = {
    "execution.checkpointing.interval" = "60s"
    "parallelism.default" = "4" 
    "table.exec.state.ttl" = "25h"  # 24시간 + 1시간 버퍼
  }
  
  rest_endpoint = confluent_flink_compute_pool.rtb_processor.rest_endpoint
  credentials {
    key    = confluent_api_key.flink_api_key.id
    secret = confluent_api_key.flink_api_key.secret
  }
  
  depends_on = [confluent_flink_statement.performance_aggregator]
}

# 🛡️ Statement 4: 중복 탐지 & 보상
resource "confluent_flink_statement" "duplicate_detector" {
  compute_pool {
    id = confluent_flink_compute_pool.rtb_processor.id
  }
  principal {
    id = confluent_service_account.flink_runner.id
  }
  
  statement = file("${path.module}/sql/duplicate_detector.sql")
  properties = {
    "execution.checkpointing.interval" = "30s"
    "parallelism.default" = "4"
    "table.exec.state.ttl" = "6h"  # 5분 윈도우 + 1시간 버퍼
  }
  
  rest_endpoint = confluent_flink_compute_pool.rtb_processor.rest_endpoint
  credentials {
    key    = confluent_api_key.flink_api_key.id
    secret = confluent_api_key.flink_api_key.secret
  }
  
  depends_on = [confluent_flink_statement.conversion_matcher]
}
```