# Worker 서버 구현 체크리스트

> **Worker 서버 책임 범위**: Flink 결과 처리, 배치 집계, 예산 동기화, 데이터 정합성 관리

---

## 🔄 Kafka 이벤트 처리

### ✅ 1. Flink 집계 결과 수신

**🎯 목적**
- [ ] Kafka Topic `performance-metrics`에서 Flink 집계 결과 수신
- [ ] 데이터베이스 성과 테이블 업데이트
- [ ] 리포트 생성용 데이터 정리

**🔧 처리 로직**
- [ ] **메시지 검증**: Flink 집계 결과 스키마 검증
- [ ] **배치 처리**: 성과 데이터 배치 업데이트로 DB 부하 최소화
- [ ] **중복 방지**: 윈도우 시작 시간 기반 중복 처리 방지
- [ ] **데이터 정합성**: 실시간 집계와 배치 집계 비교

**📝 Kafka 메시지 처리**
- [ ] **Topic**: `performance-metrics`
- [ ] **Consumer Group**: `performance-aggregator`
- [ ] **처리 내용**: 1분/5분/1시간 집계 결과 DB 저장

---

### ✅ 2. 예산 동기화 처리

**🎯 목적**
- [ ] Kafka Topic `budget-management`에서 예산 동기화 결과 수신
- [ ] Redis 카운터 보정 및 DB 동기화
- [ ] 캠페인 자동 제어 처리

**🔧 동기화 처리 로직**
- [ ] **10분 주기 동기화**: Flink에서 발송한 동기화 결과 수신
- [ ] **오차 보정**: 5% 이상 차이 시 Redis 카운터 수정
- [ ] **캠페인 제어**: 예산 임계값 도달 시 캠페인 상태 변경
- [ ] **알림 발송**: 예산 관련 이벤트 관리자 알림

**📝 Kafka 메시지 처리**
- [ ] **Topic**: `budget-management`
- [ ] **Consumer Group**: `budget-sync-processor`
- [ ] **메시지 구조**:
  ```json
  {
    "campaign_id": "12345",
    "redis_spent": 45000,
    "db_spent": 44750,
    "accuracy_ratio": 0.994,
    "sync_action": "adjust_redis",
    "campaign_action": "pause_if_exceeded"
  }
  ```

---

### ✅ 3. 품질 점수 업데이트 처리

**🎯 목적**
- [ ] Kafka Topic `quality-score-updates`에서 품질 점수 변경 수신
- [ ] 광고 품질 점수 DB 업데이트
- [ ] 점수 변화 이력 기록

**🔧 처리 로직**
- [ ] **점수 검증**: 0.0~10.0 범위 내 유효성 검증
- [ ] **변화량 확인**: 0.5점 이상 변화 시에만 업데이트
- [ ] **이력 기록**: 점수 변화 추적을 위한 이력 테이블 저장
- [ ] **알림**: 급격한 점수 하락 시 광고주 알림

**📝 Kafka 메시지 처리**
- [ ] **Topic**: `quality-score-updates`
- [ ] **Consumer Group**: `quality-score-processor`

---

## 🔄 배치 처리

### ✅ 4. 일일 집계 배치

**🎯 목적**
- [ ] 일일 성과 데이터 최종 집계
- [ ] Flink 실시간 집계 결과 검증 및 보정
- [ ] 리포트 생성용 데이터 준비

**🔧 처리 로직**
- [ ] **전일 데이터 집계**: Flink 1시간 윈도우 결과를 일별로 롤업
- [ ] **정합성 검증**: Flink 집계 vs 원시 데이터 검증
- [ ] **불일치 보정**: 5% 이상 차이 시 수동 검토 알림
- [ ] **월별 롤업**: 일별 데이터를 월별로 추가 집계

**📝 스케줄**
- [ ] **실행 시간**: 매일 새벽 2시
- [ ] **소요 시간**: 약 30분 (데이터량에 따라 가변)
- [ ] **알림**: 처리 완료 시 관리자에게 결과 알림

---

### ✅ 5. 예산 정산 배치

**🎯 목적**
- [ ] 일일 예산 사용량 최종 정산
- [ ] Redis 카운터와 DB 차감 내역 대조
- [ ] 차이 발생 시 원인 분석 및 보정

**🔧 정산 로직**
- [ ] **일별 정산**: 어제 하루 사용 예산 최종 계산
- [ ] **Redis vs DB 비교**: 일예산 카운터와 실제 차감액 비교
- [ ] **오차 분석**: 차이 발생 원인 로그 분석
- [ ] **정산 보고서**: 광고주별 일일 정산 내역 생성

---

### ✅ 6. 데이터 정리 배치

**🎯 목적**
- [ ] 오래된 이벤트 데이터 정리
- [ ] 스토리지 용량 관리
- [ ] 개인정보 보호 정책 준수

**🔧 정리 정책**
- [ ] **원시 이벤트**: 90일 후 삭제 (Kafka 토픽 보관 기간과 일치)
- [ ] **시간별 집계**: 1년 보관
- [ ] **일별 집계**: 5년 보관
- [ ] **개인식별 정보**: 30일 후 익명화
- [ ] **Redis 키**: TTL 만료된 예산 카운터 자동 정리

---

## 🚨 모니터링 및 알림

### ✅ 7. Worker 상태 모니터링

**🎯 목적**
- [ ] Worker 프로세스 상태 실시간 모니터링
- [ ] Kafka Consumer Lag 모니터링
- [ ] 처리 성능 지표 수집

**🔧 모니터링 지표**
- [ ] **Consumer Lag**: 각 토픽별 지연 시간
- [ ] **처리 속도**: 초당 처리 메시지 수
- [ ] **오류율**: 실패 비율 및 오류 유형
- [ ] **메모리 사용량**: Worker 프로세스 리소스 사용률
- [ ] **예산 동기화 정확도**: Redis-DB 간 일치 비율

**📝 알림 기준**
- [ ] Consumer Lag > 1000: Warning
- [ ] Consumer Lag > 5000: Critical
- [ ] 오류율 > 5%: Warning
- [ ] 오류율 > 10%: Critical
- [ ] 예산 동기화 정확도 < 95%: Warning

---

### ✅ 8. 데이터 일관성 모니터링

**🎯 목적**
- [ ] 실시간 집계와 배치 집계 간 일관성 검증
- [ ] 데이터 누락 또는 중복 감지
- [ ] 예산 정산 정확성 검증

**🔧 검증 로직**
- [ ] **Flink vs Worker 집계 비교**: 동일 기간 집계 결과 대조
- [ ] **Redis vs DB 예산 비교**: 일예산 카운터와 실제 차감액 비교
- [ ] **이벤트 수 검증**: Topic별 이벤트 수와 처리된 이벤트 수 비교
- [ ] **성과 지표 일관성**: CTR, CVR 계산 결과 검증

---

## ⚙️ 시스템 설정

### ✅ 9. Kafka Consumer 설정 (4개 Topic)

**🔧 Topic별 Consumer 설정**

**performance-metrics Consumer:**
- [ ] **Consumer Group**: `performance-aggregator`
- [ ] **Parallelism**: 6개 (파티션 수와 동일)
- [ ] **Batch Size**: 1000개
- [ ] **Auto Commit**: false (수동 커밋)

**budget-management Consumer:**
- [ ] **Consumer Group**: `budget-sync-processor`
- [ ] **Parallelism**: 3개
- [ ] **처리 우선순위**: P1 (높은 우선순위)
- [ ] **Retry**: 3회 재시도

**quality-score-updates Consumer:**
- [ ] **Consumer Group**: `quality-score-processor`
- [ ] **Parallelism**: 3개
- [ ] **처리 우선순위**: P2
- [ ] **Batch Size**: 500개

**📝 공통 설정**
- [ ] `session.timeout.ms`: 30000
- [ ] `enable.auto.commit`: false
- [ ] `isolation.level`: read_committed
- [ ] `fetch.min.bytes`: 512KB

---

### ✅ 10. 데이터베이스 최적화

**🔧 성능 설정**
- [ ] **Connection Pool**: 적절한 커넥션 풀 크기 설정
- [ ] **Transaction Timeout**: 트랜잭션 타임아웃 설정
- [ ] **Batch Insert**: 대량 데이터 삽입 최적화
- [ ] **Index Strategy**: 집계 쿼리 최적화를 위한 인덱스

**📝 설정 값**
- [ ] Connection Pool Size: 15-30개 (차감 처리 제거로 감소)
- [ ] Transaction Timeout: 30초
- [ ] Batch Insert Size: 1000개
- [ ] 주요 인덱스: (campaign_id, date), (advertiser_id, date)

**🔧 예산 관리 테이블 최적화**
- [ ] **빠른 조회**: (campaign_id, date) 복합 인덱스
- [ ] **정산 쿼리**: (advertiser_id, date) 인덱스
- [ ] **파티셔닝**: 월별 파티션으로 성능 최적화

---

### ✅ 11. Redis 연동 설정

**🔧 예산 카운터 관리**
- [ ] **읽기 전용 접근**: Worker는 Redis 읽기만 수행
- [ ] **연결 풀**: Redis 클러스터 연결 풀 관리
- [ ] **장애 복구**: Redis 연결 실패 시 DB 우선 처리
- [ ] **캐시 무효화**: 예산 보정 시 관련 캐시 무효화

**📝 설정 값**
- [ ] Redis Connection Pool: 10개
- [ ] Connection Timeout: 5초
- [ ] Read Timeout: 3초
- [ ] Retry Policy: 3회 재시도

---

### ✅ 12. 장애 복구 절차

**🔧 복구 시나리오**
- [ ] **Worker 프로세스 재시작**: 자동 재시작 및 상태 복구
- [ ] **Kafka 연결 실패**: 재연결 로직 및 백오프 전략
- [ ] **데이터베이스 장애**: 읽기 전용 모드 전환
- [ ] **메시지 처리 실패**: DLQ를 통한 수동 복구
- [ ] **예산 동기화 실패**: 수동 Redis 카운터 보정

**📝 복구 절차서**
- [ ] 장애 감지 → 자동 알림 → 담당자 확인 → 복구 작업 → 검증 → 정상화 확인

---

### ✅ 13. 성능 최적화

**🔧 처리량 개선**
- [ ] **배치 처리**: 단건 처리 대신 배치 처리로 DB 부하 감소
- [ ] **비동기 처리**: 블로킹 I/O 최소화
- [ ] **메모리 관리**: JVM 힙 메모리 최적화
- [ ] **스레드 풀**: 적절한 스레드 풀 크기 설정

**📝 목표 성능**
- [ ] **성과 집계 처리**: 5,000 메시지/초
- [ ] **예산 동기화**: 500 메시지/초  
- [ ] **품질 점수 업데이트**: 1,000 메시지/초
- [ ] **Consumer Lag**: < 1,000개 유지

이제 Worker 서버는 클릭 차감 처리에서 해방되어 더욱 안정적이고 단순한 구조로 운영됩니다! 