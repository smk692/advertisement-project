# 📊 선행 데이터 체크리스트

## 📋 목차
1. [언급되어 있는 선행 데이터](#-언급되어-있는-선행-데이터)
2. [누락된 중요 선행 데이터](#-누락된-중요-선행-데이터)
3. [PO 확인 필요한 정책적 이슈](#-po-확인-필요한-정책적-이슈)
4. [즉시 해결 필요한 데이터 갭](#-즉시-해결-필요한-데이터-갭)
5. [권장 해결 방안](#-권장-해결-방안)
6. [결론 및 액션 아이템](#-결론-및-액션-아이템)

---

## ✅ **언급되어 있는 선행 데이터**

### 1. **알고리즘 파라미터**
**현재 상태**: ✅ 언급됨
- `α` (전환율 가중치) - "기존 시스템의 세팅으로 런칭"
- `π` (데이터 수집 기간) - "기존 시스템의 세팅으로 런칭"  
- `ω1, ω2` (임계값) - "1시간 평균 이하 시"
- `δ` (방어값 추정법) - "평균 or 최소"

**출처**: `1-0 RTB_요구사항.md`

### 2. **마이그레이션 계획**
**현재 상태**: ✅ 개략적 언급
- "Citrus Ad 시스템에서 기존 데이터 동기화 모듈 개발"
- "초기 파라미터 추정 작업 수행"

**출처**: `1-0 RTB_요구사항.md`, `1-1. 요구사항.md`

---

## ❌ **누락된 중요 선행 데이터**

### 1. **CTR/CVR 초기 데이터** 🚨
**문제점**: 구체적인 데이터 수집 방안 없음
```
필요한 데이터:
- 상품별 × 영역별 CTR/CVR 이력 (최소 30일)
- 카테고리별 평균 CTR/CVR (방어값 계산용)
- 디바이스/시간대별 성과 패턴
```

### 2. **상품 마스터 데이터** 🚨
**문제점**: 품질 점수 산정 기준 불명확
```
필요한 데이터:
- 상품별 품질 점수 (0.00~10.0) 초기값
- 카테고리 계층 구조 완전한 매핑
- 상품별 과거 판매 실적 (인기도 계산용)
```

### 3. **검색어 광고 매칭 데이터** 🚨 **[NEW]**
**문제점**: 검색어 기반 광고 매칭을 위한 키워드 데이터 부족
```
필요한 데이터:
- 캠페인별 타겟 키워드 목록
- 키워드별 매칭 우선순위
- 유사어/동의어 매핑 테이블
- 검색어별 과거 성과 데이터
```

### 4. **가격 실험 매핑 데이터** 🚨 **[NEW]**
**문제점**: A/B 테스트를 위한 상품 매핑 정보 부족
```
필요한 데이터:
- 실험 키/변수별 상품 매핑 테이블
- 기존 A/B 테스트 결과 데이터
- 실험군별 성과 차이 분석
- 통계적 유의성 검증 기준
```

### 5. **예산 관리 초기 설정값** ⚠️ **[UPDATED]**
**문제점**: Redis 카운터 및 동기화를 위한 기준값 부족
```
필요한 설정:
- 캠페인별 일예산 기준값
- 예산 알림 임계값 (80%, 95%)
- Redis 카운터 오차 허용 범위 (5%)
- 10분 동기화 주기의 비즈니스 타당성
```

### 6. **사용자 행동 이력** 🚨
**문제점**: 개인화 기능을 위한 기초 데이터 수집 방안 없음
```
필요한 데이터:
- 사용자별 과거 클릭/구매 이력
- 세션별 행동 패턴
- 디바이스별 사용자 매핑
- 24시간 매칭을 위한 세션/디바이스 연계 데이터
```

### 7. **경쟁사/시장 데이터** ⚠️
**문제점**: 입찰가 설정을 위한 시장 정보 부족
```
필요한 정보:
- 카테고리별 평균 입찰가 수준
- 경쟁사 광고 성과 벤치마크
- 시장 CPM/CPC 수준
```

---

## 🚨 **PO 확인 필요한 정책적 이슈**

### **1. 입찰가 변경 시 처리 정책** 🚨 **[NEW - 긴급]**
**문제점**: 입찰가 변경 시 기존 노출과 신규 요청의 처리 방침이 불명확

#### **핵심 이슈: 점진적 적용 vs 즉시 반영**
**🎯 결정이 필요한 이유**: 사용자 경험, 시스템 성능, 광고주 만족도에 직접적 영향

**시나리오 예시**
```
상황: 광고주가 오전 10시에 입찰가를 1000원 → 1500원으로 변경
문제: 오전 9시에 노출된 광고가 오후 2시에 클릭되면?

옵션 A: 점진적 적용 (권장)
- 기존 노출: 1000원으로 과금 (노출 시점 조건 유지)
- 신규 요청: 1500원으로 새로운 순위 계산
- 장점: 사용자 경험 일관성, 시스템 안정성
- 단점: 광고주 변경사항 반영 지연

옵션 B: 즉시 반영
- 모든 노출: 즉시 1500원 기준으로 재계산
- 기존 광고 순위도 실시간 변경
- 장점: 광고주 요구사항 즉시 반영
- 단점: 사용자 혼란, 시스템 부하 급증
```

#### **Q1. 캐시 업데이트 정책 결정**
**시스템 성능 vs 실시간성 트레이드오프**

**옵션 A: 고성능형 (15-30분 지연)**
```
- 캐시 TTL: 30분
- 업데이트 주기: 15분마다 배치
- 장점: 시스템 안정성, 낮은 부하
- 단점: 광고주 불만 가능성
- 적용: 안정성 우선 시스템
```

**옵션 B: 균형형 (5-10분 지연)**
```
- 캐시 TTL: 10분
- 업데이트 주기: 5분마다 배치
- 장점: 적당한 실시간성, 관리 가능한 부하
- 단점: 중간 수준의 복잡도
- 적용: 일반적인 상용 시스템
```

**옵션 C: 고실시간형 (1-2분 지연)**
```
- 캐시 TTL: 2분
- 업데이트 주기: 1분마다
- 장점: 높은 실시간성, 광고주 만족도
- 단점: 높은 시스템 부하, 복잡한 관리
- 적용: 경쟁이 치열한 시장
```

#### **Q2. 업계 벤치마크 대비 정책**
**경쟁사 수준 vs 차별화 전략**

**업계 현황**
```
Google Ads: 15분~2시간 (광고 유형별 차등)
Facebook Ads: 15분~1시간 (알고리즘 학습 고려)
네이버 검색광고: 10분~30분
Amazon Ads: 30분~2시간

일반적 기준: 15분 이내 = 빠름, 30분 이내 = 보통, 1시간 이상 = 느림
```

**권장 전략**
```
Phase 1 (출시): 30분 지연 (안정성 우선)
Phase 2 (3개월 후): 15분 지연 (시장 평균)
Phase 3 (6개월 후): 10분 지연 (차별화)
```

#### **Q3. 예외 상황 처리 방침**
**급격한 변경 vs 일반적 조정**

**급격한 변경 감지 기준**
```
- 입찰가 50% 이상 증감
- 일예산 100% 이상 증가
- 캠페인 긴급 중단 요청

처리 방식:
- 일반 변경: 정규 업데이트 주기 따름
- 급격한 변경: 우선 반영 (5분 이내)
- 긴급 중단: 즉시 반영 (1분 이내)
```

### **2. 비즈니스 로직 및 계산 공식 정의** 🚨 **[NEW]**
**문제점**: 핵심 지표의 구체적인 계산 방법과 데이터 범위가 불명확

#### **Q1. 카테고리별 평균 CTR/CVR 계산 공식 정의**
**🎯 결정이 필요한 이유**: 방어값 계산과 신규 상품 성과 예측의 기준이 됨

**옵션 A: 단기 집중형 (30일 기준)**
```
- 계산 기간: 최근 30일 데이터만 사용
- 장점: 최신 트렌드 반영, 계절성 대응
- 단점: 샘플 부족 가능성, 변동성 높음
- 적용 예시: 패션, 계절상품
```

**옵션 B: 안정성 중심형 (90일 기준)**
```
- 계산 기간: 최근 90일 데이터 사용
- 장점: 안정적 평균값, 충분한 샘플
- 단점: 트렌드 변화 반영 지연
- 적용 예시: 생필품, 전자기기
```

**추가 결정 사항:**
- **이상치 제거**: 상위/하위 5% 제거 vs 2σ 기준
- **시간대 필터링**: 새벽 0-6시 제외 여부 (봇 트래픽 대응)
- **디바이스별 분리**: 모바일/PC 별도 계산 여부

#### **Q2. 상품 품질 점수 계산 공식 (0.00~10.0)**
**🎯 결정이 필요한 이유**: RTB 알고리즘의 P 파라미터로 직접 사용됨

**제안 공식 A: 판매 중심형**
```
품질점수 = (판매량 40% + 리뷰점수 30% + CTR성과 20% + 반품률 10%)

세부 계산:
- 판매량 점수 = min(10, 월판매량/카테고리평균 × 5)
- 리뷰 점수 = (평균별점/5.0) × 10
- CTR 성과 = min(10, 상품CTR/카테고리평균CTR × 5)
- 반품률 점수 = max(0, 10 - 반품률×100)
```

**제안 공식 B: 균형형**
```
품질점수 = (판매량 30% + 리뷰점수 25% + CTR성과 25% + CVR성과 20%)

장점: 광고 성과도 반영
단점: 신규 상품에 불리
```

**추가 결정 사항:**
- **신규 상품 초기값**: 5.0 고정 vs 카테고리 평균
- **업데이트 주기**: 실시간 vs 일별 vs 주별
- **카테고리별 가중치 차등**: 패션(리뷰 중시) vs 전자기기(스펙 중시)

#### **Q3. 알고리즘 파라미터 구체적 수치 결정**
**🎯 결정이 필요한 이유**: RTB 점수 계산의 핵심 파라미터

**α (전환율 가중치) 결정**
```
옵션 A: α = 0.2 (클릭 중심)
- 의미: 전환 보너스는 기본 점수의 20%
- 적용: 브랜딩 목적, 신규 고객 유입 중시
- 수식: S = 입찰가×CTR + 0.2×CTR×CVR×P

옵션 B: α = 0.5 (균형형)  
- 의미: 클릭과 전환을 동등하게 중시
- 적용: 일반적인 커머스 광고

옵션 C: α = 1.0 (전환 중심)
- 의미: 전환이 클릭만큼 중요
- 적용: 고가 상품, ROI 중시
```

**π (데이터 수집 기간) 결정**
```
옵션 A: π = 7일
- 장점: 빠른 트렌드 반영, 신선한 데이터
- 단점: 주간 변동성, 샘플 부족 위험

옵션 B: π = 30일
- 장점: 안정적 예측, 충분한 샘플
- 단점: 트렌드 변화 반영 지연
```

**ω1, ω2 (임계값) 구체적 수치**
```
ω1 (CTR 계산 최소 노출수): 100회? 500회? 1000회?
ω2 (CVR 계산 최소 클릭수): 10회? 50회? 100회?

권장: ω1=500회, ω2=20회
- 근거: 통계적 유의성 확보 + 실용성 균형
```

#### **Q4. 방어값 적용 조건 및 계층 구조**
**🎯 결정이 필요한 이유**: 데이터 부족 시 시스템 안정성 확보

**방어값 선택 기준**
```
δ = "평균" 적용 조건:
- 신규 상품 런칭 시 (공정한 기회 제공)
- 카테고리 경쟁이 치열한 경우
- 브랜드 인지도가 있는 상품

δ = "최소" 적용 조건:
- 리스크 회피 필요 시
- 예산이 제한적인 광고주
- 실험적 상품/카테고리
```

**카테고리 계층 우선순위**
```
1순위: 중분류 평균 (가장 구체적)
2순위: 대분류 평균 (일반화)
3순위: 전체 평균 (최후 방어선)

예시: "게임 > RPG > MMORPG" 상품
- 1순위: RPG 카테고리 평균 CTR/CVR
- 2순위: 게임 카테고리 평균 CTR/CVR
- 3순위: 전체 평균 CTR/CVR
```

#### **Q5. P (상품 관련 가중치) 정의 및 계산**
**🎯 결정이 필요한 이유**: RTB 수식의 핵심 변수이지만 정의가 모호함

**옵션 A: 품질점수 연동형**
```
P = quality_score × 10
- 품질점수 5.0 → P = 50
- 품질점수 8.5 → P = 85
- 장점: 품질과 직접 연관
- 단점: 품질점수 의존성 높음
```

**옵션 B: 고정값 + 보정형**
```
P = 100 + (quality_score - 5.0) × 20
- 품질점수 5.0 → P = 100 (기준)
- 품질점수 8.0 → P = 160 (60% 가산)
- 장점: 안정적 기준값 + 차등화
```

**옵션 C: 카테고리별 차등형**
```
P = category_base_score + quality_bonus
- 고가상품(전자): base=150, bonus=품질점수×30
- 저가상품(생필): base=80, bonus=품질점수×20
- 장점: 카테고리 특성 반영
- 단점: 관리 복잡도 증가
```

### **3. A/B 테스트 및 실험 정책** 🚨 **[NEW]**
**문제점**: 가격 실험 및 알고리즘 테스트 범위와 안전장치가 불명확

#### **Q1. 실험 범위 및 트래픽 분할 정책**
**🎯 결정이 필요한 이유**: 실험 영향도와 비즈니스 리스크 통제

**실험 트래픽 비율**
```
옵션 A: 보수적 접근 (5-10%)
- 전체 트래픽의 5-10%만 실험 대상
- 장점: 낮은 리스크, 안정적 운영
- 단점: 실험 결과 도출 시간 오래 걸림
- 적용: 시스템 초기 단계

옵션 B: 균형 접근 (15-20%)
- 전체 트래픽의 15-20% 실험 대상
- 장점: 적당한 실험 속도, 관리 가능한 리스크
- 단점: 중간 수준의 비즈니스 영향
- 적용: 안정화 후 일반 운영

옵션 C: 적극적 접근 (25-30%)
- 전체 트래픽의 25-30% 실험 대상
- 장점: 빠른 실험 결과, 혁신적 개선
- 단점: 높은 리스크, 잠재적 매출 영향
- 적용: 성숙한 시스템, 경쟁 우위 확보
```

**실험 제외 대상**
```
필수 제외:
- VIP 광고주 (매출 상위 10%)
- 브랜드 검색 (고전환 키워드)
- 이벤트/프로모션 기간

선택적 제외:
- 신규 광고주 (런칭 3개월 미만)
- 고가 상품 (100만원 이상)
- 특정 카테고리 (의료, 금융 등)
```

#### **Q2. 통계적 유의성 및 실험 기간**
**🎯 결정이 필요한 이유**: 실험 신뢰도와 의사결정 속도 균형

**실험 기간 설정**
```
최소 실험 기간 옵션:

옵션 A: 단기 집중형 (7일)
- 기간: 7일 최소, 14일 권장
- 장점: 빠른 의사결정, 민첩한 개선
- 조건: 일 트래픽 1만 이상, 명확한 지표
- 적용: 명백한 개선, UI/UX 변경

옵션 B: 중기 안정형 (14일)
- 기간: 14일 최소, 21일 권장
- 장점: 안정적 결과, 주간 변동 흡수
- 조건: 충분한 샘플, 복합 지표 분석
- 적용: 알고리즘 변경, 가격 정책

옵션 C: 장기 검증형 (28일)
- 기간: 28일 최소, 60일 권장
- 장점: 계절성 반영, 높은 신뢰도
- 조건: 중대한 변경, 전략적 의사결정
- 적용: 근본적 알고리즘 변경
```

**통계적 유의성 기준**
```
신뢰도 수준:
- p-value < 0.05 (95% 신뢰도) - 일반적 기준
- p-value < 0.01 (99% 신뢰도) - 중요한 변경
- p-value < 0.001 (99.9% 신뢰도) - 핵심 알고리즘

최소 샘플 크기:
- CTR 개선: 각 그룹별 최소 1,000 클릭
- CVR 개선: 각 그룹별 최소 100 전환
- 매출 개선: 각 그룹별 최소 50 구매
```

#### **Q3. 실험 모니터링 및 자동 중단 정책**
**🎯 결정이 필요한 이유**: 실험 실패 시 비즈니스 손실 최소화

**자동 중단 트리거**
```
Critical 수준 (즉시 중단):
- CTR 30% 이상 하락
- CVR 40% 이상 하락  
- 매출 20% 이상 하락
- 오류율 5% 이상 증가

Warning 수준 (24시간 모니터링):
- CTR 15% 이상 하락
- CVR 20% 이상 하락
- 매출 10% 이상 하락
- 응답시간 50% 이상 증가

Normal 수준 (정상 진행):
- 위 기준 미만의 변화
- 통계적 유의성 달성 시까지 진행
```

**롤백 전략**
```
자동 롤백:
- Critical 수준 도달 시 10분 내 자동 롤백
- 시스템 장애 발생 시 즉시 롤백
- 예상치 못한 부작용 감지 시

수동 개입:
- Warning 수준에서 PO/개발팀 판단
- 비즈니스 요구사항 변경 시
- 외부 환경 변화 (이벤트, 경쟁사 동향)

점진적 롤백:
- 실험 트래픽을 단계적으로 줄여가며 안전하게 복구
- Phase 1: 30% → 20% → 10% → 0%
- 각 단계별 30분 모니터링 후 진행
```

#### **Q4. 실험 결과 평가 및 적용 기준**
**🎯 결정이 필요한 이유**: 실험 성공 기준과 전면 적용 판단

**성공 기준**
```
Tier 1 지표 (필수 개선):
- CTR 향상: +5% 이상
- CVR 향상: +10% 이상
- ROAS 향상: +8% 이상

Tier 2 지표 (부가 고려):
- 사용자 경험: 클릭률, 체류시간
- 시스템 성능: 응답시간, 부하
- 운영 효율성: 관리 복잡도

최종 적용 결정:
- Tier 1 중 2개 이상 개선 + Tier 2 악화 없음
- 통계적 유의성 확보 + 비즈니스 타당성
- 기술적 안정성 + 운영 지속가능성
```

---

## 🎯 **즉시 해결 필요한 데이터 갭**

### **P0: PO 정책 결정 후 진행 가능** 🚨
1. **입찰가 변경 처리 정책** - 즉시 vs 지연 반영 방침 결정
2. **비즈니스 로직 계산 공식** - CTR/CVR 평균, 품질 점수, 알고리즘 파라미터
3. **A/B 테스트 범위 및 정책** - 실험 대상, 기간, 롤백 기준

### **P1: 새로운 아키텍처 필수 데이터** 
1. **검색어 매칭 데이터** - 캠페인별 타겟 키워드 및 매칭 로직
2. **가격 실험 매핑** - 실험군별 상품 변환 테이블
3. **Redis 예산 카운터 초기값** - 캠페인별 일예산 및 임계값
4. **24시간 매칭 데이터** - 세션/디바이스 기반 사용자 추적

### **P2: 알고리즘 동작을 위한 필수 데이터**
1. **CTR/CVR 초기값 수집 계획** - Citrus Ad 데이터 추출 방안
2. **카테고리별 방어값 산정** - 평균/최소값 계산 로직
3. **상품 품질 점수 초기화** - 판매량/리뷰 기반 점수 산정

### **P3: 시스템 안정성을 위한 설정값**
1. **알고리즘 파라미터 구체적 수치** - α=0.3이라면 근거는?
2. **영역별 기본 설정값** - 최대 광고 수, 품질 점수 기준
3. **캐시 TTL 및 동기화 주기** - PO 정책에 따라 결정

### **P4: 개인화/최적화를 위한 확장 데이터**
1. **사용자 세그먼트 정의** - 연령/성별/지역별 행동 패턴
2. **시즌/이벤트 패턴** - 특정 기간 성과 변화 이력
3. **A/B 테스트 기준선** - 기존 성과 대비 개선 목표

---

## 📋 **권장 해결 방안 (업데이트)**

### **1단계: 새로운 기능 데이터 준비** **[NEW]**
```
- 검색어 광고: 캠페인별 키워드 목록 수집 및 매핑
- 가격 실험: 실험 설계 및 상품 매핑 테이블 구축
- 예산 관리: Redis 카운터 초기값 및 동기화 정책 수립
- 매칭 로직: 세션/디바이스 추적을 위한 데이터 구조 설계
```

### **2단계: 기존 데이터 분석**
```
- Citrus Ad 시스템 데이터 분석
- 최근 3개월 CTR/CVR 데이터 추출
- 상품별 성과 히스토리 수집
- 검색어별 과거 매칭 성과 분석
```

### **3단계: 초기값 산정**
```
- 카테고리별 평균 성과 계산
- 상품별 품질 점수 자동 산정
- 알고리즘 파라미터 백테스팅
- 실험 매핑의 통계적 유의성 검증
```

### **4단계: 검증 및 조정**
```
- A/B 테스트로 성과 비교
- 점진적 파라미터 최적화
- 실시간 모니터링 기반 조정
- Redis 동기화 정확도 모니터링
```

---

---

## 📋 **결론 및 액션 아이템**

### **🚨 PO 긴급 결정 필요 (개발 착수 전 필수)**

#### **📊 의사결정 매트릭스**
| 이슈 | 결정 기한 | 영향도 | 복잡도 | 우선순위 |
|------|-----------|--------|--------|----------|
| **입찰가 변경 처리 정책** | 3일 이내 | 🔴 High | 🔴 High | P0 |
| **비즈니스 로직 계산 공식** | 5일 이내 | 🔴 High | 🟡 Medium | P0 |
| **A/B 테스트 범위 및 정책** | 7일 이내 | 🟡 Medium | 🟡 Medium | P1 |

#### **📋 결정 체크리스트**
**입찰가 변경 처리 정책 (3일 내 결정 필수)**
- [ ] 점진적 적용 vs 즉시 반영 방침
- [ ] 캐시 업데이트 주기 (5분/10분/30분)
- [ ] 예외 상황 처리 방침 (급격한 변경 기준)
- [ ] 업계 벤치마크 대비 목표 수준

**비즈니스 로직 계산 공식 (5일 내 결정 필수)**
- [ ] CTR/CVR 평균 계산 기간 (30일/90일)
- [ ] 상품 품질 점수 가중치 비율
- [ ] 알고리즘 파라미터 구체적 수치 (α, π, ω)
- [ ] P 파라미터 계산 공식 선택

**A/B 테스트 정책 (7일 내 결정)**
- [ ] 실험 트래픽 비율 (5-10%/15-20%/25-30%)
- [ ] 최소 실험 기간 (7일/14일/28일)
- [ ] 자동 중단 트리거 기준
- [ ] 성공 기준 및 적용 조건

### **📊 즉시 필요한 액션 아이템 (재조정)**

**Phase 1: PO 정책 결정 (1주일)**
1. **입찰가 변경 정책 수립** - 즉시 vs 지연 반영 방침
2. **비즈니스 로직 공식 확정** - CTR/CVR 계산, 품질 점수, 알고리즘 파라미터
3. **A/B 테스트 정책 확정** - 실험 범위, 기간, 롤백 기준

**Phase 2: 핵심 데이터 구축 (3주일)**
1. **검색어 매칭 데이터 구축** (21일) - 캠페인별 타겟 키워드 수집
2. **가격 실험 매핑 테이블 설계** (14일) - 실험군별 상품 변환 로직
3. **Redis 예산 카운터 설정** (14일) - 캠페인별 일예산 및 임계값
4. **Citrus Ad 데이터 추출 작업** (21일) - CTR/CVR 이력 데이터

**Phase 3: 시스템 설정 (2주일)**
1. **상품 품질 점수 산정 로직** (14일) - 자동 점수 계산
2. **카테고리별 방어값 계산** (7일) - 평균/최소값 정책
3. **알고리즘 파라미터 구체적 수치** (7일) - 백테스팅 기반

### **🎯 핵심 성공 요소 (업데이트)**
- **정책 일관성**: 입찰가 변경부터 과금까지 일관된 처리 정책
- **성능 안정성**: 캐시 전략으로 시스템 부하 최소화  
- **데이터 품질**: 검색어 매칭 정확도로 노출 품질 보장
- **실험 신뢰성**: 통계적으로 유의한 A/B 테스트 설계
- **운영 효율성**: 자동화된 모니터링과 알림 체계

### **📈 개발 착수 조건**
✅ **PO 정책 결정 완료** (입찰가 변경, 비즈니스 로직 공식, A/B 테스트)  
✅ **핵심 데이터 준비 완료** (검색어, 실험 매핑, 예산 카운터, CTR/CVR)  
✅ **시스템 설정값 확정** (구체적 파라미터 수치, 방어값 적용 조건)

**⏰ 예상 준비 기간**: PO 결정 후 4-5주 내 개발 착수 가능 