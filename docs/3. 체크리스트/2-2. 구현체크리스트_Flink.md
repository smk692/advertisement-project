# Flink 스트림 처리 구현 체크리스트

> **Flink 책임 범위**: 실시간 스트림 처리, 이벤트 매칭, 윈도우 집계, 이상 감지, 예산 동기화

---

## 🚀 핵심 스트림 처리 Job

### ✅ 1. 실시간 성과 지표 집계 Job

**🎯 목적**
- [ ] 1분/5분/1시간 윈도우별 CTR, CVR, CPC 실시간 계산
- [ ] 광고별, 캠페인별, 광고주별 성과 지표 집계
- [ ] API 서버에서 사용할 실시간 지표 Redis 업데이트

**🔧 처리 로직**
- [ ] **이벤트 소비**: Kafka Topic `ad-events`에서 노출, 클릭, 전환 이벤트 통합 처리
- [ ] **윈도우 집계**: Tumbling Window (1분, 5분, 1시간) 기반 집계
- [ ] **상태 관리**: Flink State Backend를 통한 안정적인 카운터 관리
- [ ] **출력**: Redis Sink를 통한 실시간 지표 업데이트

**📝 Flink SQL 구현**
```sql
-- 통합 이벤트 스트림에서 1분 윈도우 실시간 성과 지표
CREATE TABLE realtime_metrics AS
SELECT 
    ad_id,
    campaign_id,
    advertiser_id,
    TUMBLE_START(event_time, INTERVAL '1' MINUTE) as window_start,
    COUNT(*) FILTER (WHERE event_type = 'IMPRESSION') as impressions,
    COUNT(*) FILTER (WHERE event_type = 'CLICK') as clicks,
    COUNT(*) FILTER (WHERE event_type = 'CONVERSION') as conversions,
    SUM(actual_price) FILTER (WHERE event_type = 'CLICK') as total_cost,
    SUM(conversion_value) FILTER (WHERE event_type = 'CONVERSION') as total_revenue,
    CASE 
        WHEN COUNT(*) FILTER (WHERE event_type = 'IMPRESSION') > 0 
        THEN CAST(COUNT(*) FILTER (WHERE event_type = 'CLICK') AS DOUBLE) / COUNT(*) FILTER (WHERE event_type = 'IMPRESSION') * 100 
        ELSE 0 
    END as ctr,
    CASE 
        WHEN COUNT(*) FILTER (WHERE event_type = 'CLICK') > 0 
        THEN CAST(COUNT(*) FILTER (WHERE event_type = 'CONVERSION') AS DOUBLE) / COUNT(*) FILTER (WHERE event_type = 'CLICK') * 100 
        ELSE 0 
    END as cvr
FROM ad_events
GROUP BY ad_id, campaign_id, advertiser_id, TUMBLE(event_time, INTERVAL '1' MINUTE);
```

**📝 Redis 출력 구조**
- [ ] `ad:{ad_id}:metrics:1m`: 1분 윈도우 지표
- [ ] `campaign:{campaign_id}:metrics:5m`: 5분 윈도우 지표
- [ ] `advertiser:{advertiser_id}:metrics:1h`: 1시간 윈도우 지표

---

### ✅ 2. 클릭-전환 매칭 Job (CEP)

**🎯 목적**
- [ ] 클릭 후 24시간 내 전환 이벤트 매칭
- [ ] 세션/디바이스 기반 기여 모델 적용
- [ ] 다중 터치포인트 분석 및 기여도 계산

**🔧 CEP 패턴 정의**
- [ ] **Primary 매칭**: session_id 기반 클릭-전환 매칭
- [ ] **Fallback 매칭**: device_id + 시간 윈도우 기반 매칭
- [ ] **기여 모델**: Last-Click Attribution (최근 클릭에 100% 기여)
- [ ] **시간 윈도우**: 24시간 이내 전환만 유효

**📝 CEP 패턴 구현**
```java
// 클릭 후 24시간 내 전환 매칭
Pattern<Event, ?> clickToConversionPattern = Pattern
    .<Event>begin("click")
    .where(SimpleCondition.of(event -> 
        event.getEventType().equals("CLICK")))
    .followedBy("conversion")
    .where(SimpleCondition.of(event -> 
        event.getEventType().equals("CONVERSION")))
    .where(new IterativeCondition<Event>() {
        @Override
        public boolean filter(Event event, Context<Event> ctx) throws Exception {
            Event clickEvent = ctx.getEventsForPattern("click").iterator().next();
            return event.getSessionId().equals(clickEvent.getSessionId()) ||
                   event.getDeviceId().equals(clickEvent.getDeviceId());
        }
    })
    .within(Time.hours(24));
```

**📝 매칭 결과 출력**
- [ ] **Kafka Topic**: `performance-metrics` (집계 결과용)
- [ ] **Redis**: 실시간 CVR 지표 직접 업데이트
- [ ] **모니터링**: 매칭 성공률 및 지연시간 메트릭

---

### ✅ 3. 예산 동기화 Job

**🎯 목적**
- [ ] Redis 일예산 카운터와 DB 간 10분마다 동기화
- [ ] 카운터 정확성 보장 및 오차 수정
- [ ] 예산 초과 시 자동 캠페인 일시정지

**🔧 동기화 로직**
- [ ] **10분 윈도우**: Tumbling Window로 주기적 동기화
- [ ] **정확성 검증**: Redis 카운터 vs DB 실제 차감액 비교
- [ ] **오차 수정**: 5% 이상 차이 시 Redis 카운터 보정
- [ ] **자동 제어**: 95% 예산 소진 시 캠페인 자동 일시정지

**📝 동기화 구현**
```java
// 10분마다 예산 동기화
DataStream<BudgetSync> budgetSync = clickStream
    .filter(event -> "CLICK".equals(event.getEventType()))
    .keyBy(Event::getCampaignId)
    .window(TumblingEventTimeWindows.of(Time.minutes(10)))
    .aggregate(new BudgetSyncAggregator())
    .map(new BudgetSyncFunction());

// 예산 초과 감지 및 캠페인 제어
budgetSync
    .filter(sync -> sync.getBudgetUsageRatio() > 0.95)
    .addSink(new CampaignControlSink()); // 자동 일시정지
```

**📝 동기화 출력**
- [ ] **Kafka Topic**: `budget-management` (캠페인 제어 및 알림)
- [ ] **Redis 업데이트**: 보정된 일예산 카운터
- [ ] **알림**: 예산 임계값 도달 시 관리자 알림

---

### ✅ 4. 실시간 이상 감지 Job

**🎯 목적**
- [ ] 비정상적인 클릭 패턴 실시간 감지 (봇 트래픽, 클릭 폭증 등)
- [ ] 광고 성과 급변 감지 및 알림
- [ ] 품질 점수 급락 감지

**🔧 이상 감지 알고리즘**
- [ ] **클릭률 이상**: 평소 CTR 대비 10배 이상 급증
- [ ] **클릭 패턴 이상**: 동일 IP/디바이스에서 단시간 대량 클릭
- [ ] **전환율 이상**: CVR이 평소 대비 급격히 하락
- [ ] **품질 점수 이상**: 1시간 내 품질 점수 2점 이상 하락

**📝 이상 감지 구현**
```java
// CTR 급증 감지 (1분 윈도우)
DataStream<Alert> ctrAnomalyAlerts = adEventsStream
    .filter(event -> "CLICK".equals(event.getEventType()) || "IMPRESSION".equals(event.getEventType()))
    .keyBy(Event::getAdId)
    .window(TumblingEventTimeWindows.of(Time.minutes(1)))
    .aggregate(new CTRAggregator(), new CTRAnomalyDetector())
    .filter(alert -> alert.getCurrentCTR() > alert.getHistoricalCTR() * 10);

// 동일 디바이스 대량 클릭 감지
DataStream<Alert> clickSpamAlerts = adEventsStream
    .filter(event -> "CLICK".equals(event.getEventType()))
    .keyBy(Event::getDeviceId)
    .window(TumblingEventTimeWindows.of(Time.minutes(1)))
    .aggregate(new ClickCountAggregator())
    .filter(count -> count > 100); // 1분간 100회 이상 클릭
```

**📝 알림 출력**
- [ ] **Kafka Topic**: `quality-score-updates` (품질 점수 조정)
- [ ] **Slack/Email**: 관리자 즉시 알림
- [ ] **대시보드**: 실시간 이상 상황 표시

---

## 📊 고급 분석 Job

### ✅ 5. 사용자 행동 분석 Job

**🎯 목적**
- [ ] 사용자별 광고 상호작용 패턴 분석
- [ ] 실시간 개인화 스코어 계산
- [ ] 리타겟팅 대상 실시간 식별

**🔧 분석 로직**
- [ ] **세션 분석**: 사용자 세션 내 광고 상호작용 패턴
- [ ] **관심도 스코어**: 클릭/전환 이력 기반 카테고리별 관심도
- [ ] **리타겟팅 신호**: 장바구니 추가 후 미구매, 상품 상세 조회 등

**📝 사용자 프로파일 업데이트**
- [ ] **Redis**: 실시간 사용자 프로파일 업데이트
- [ ] **추천 시스템**: 실시간 추천 스코어 피드

---

### ✅ 6. 품질 점수 업데이트 Job

**🎯 목적**
- [ ] 실시간 성과 데이터 기반 품질 점수 업데이트
- [ ] CTR, CVR 변화에 따른 자동 점수 조정
- [ ] 경쟁 상황 반영한 상대적 품질 평가

**🔧 업데이트 로직**
- [ ] **1시간 윈도우**: 최근 1시간 성과 기반 점수 재계산
- [ ] **점수 평활화**: 급격한 변화 방지를 위한 가중평균 적용
- [ ] **임계값 기반 업데이트**: 0.5점 이상 변화 시에만 업데이트

**📝 점수 업데이트 출력**
- [ ] **Kafka Topic**: `quality-score-updates`
- [ ] **Redis**: 실시간 품질 점수 캐시 업데이트
- [ ] **DB**: 배치로 최종 점수 저장

---

## 🔧 시스템 설정 및 최적화

### ✅ 7. Flink 클러스터 설정

**🔧 클러스터 구성**
- [ ] **JobManager**: 고가용성을 위한 HA 설정
- [ ] **TaskManager**: 메모리 및 CPU 최적화 설정
- [ ] **Parallelism**: 각 Job별 최적 병렬도 설정
- [ ] **Checkpointing**: 장애 복구를 위한 체크포인트 설정

**📝 성능 설정**
```yaml
# flink-conf.yaml
jobmanager.memory.process.size: 2g
taskmanager.memory.process.size: 8g
taskmanager.numberOfTaskSlots: 4
parallelism.default: 16

# Checkpointing
execution.checkpointing.interval: 60s
execution.checkpointing.mode: EXACTLY_ONCE
state.backend: rocksdb
state.checkpoints.dir: hdfs://checkpoints
```

---

### ✅ 8. 상태 관리 최적화

**🔧 State Backend 설정**
- [ ] **RocksDB**: 대용량 상태 데이터 처리
- [ ] **TTL 설정**: 오래된 상태 자동 정리
- [ ] **압축**: 상태 데이터 압축으로 메모리 절약
- [ ] **백업**: HDFS/S3 기반 상태 백업

**📝 TTL 설정 예시**
```java
// 24시간 TTL 설정 (클릭-전환 매칭용)
StateTtlConfig ttlConfig = StateTtlConfig
    .newBuilder(Time.hours(24))
    .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)
    .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)
    .build();

ValueStateDescriptor<ClickEvent> clickStateDescriptor = 
    new ValueStateDescriptor<>("click-state", ClickEvent.class);
clickStateDescriptor.enableTimeToLive(ttlConfig);
```

---

### ✅ 9. Kafka 설정 (4개 Topic)

**📝 Topic 구성**
- [ ] **ad-events** (P0): 노출, 클릭, 전환 통합 이벤트
  - Partitions: 12, Replication: 3
  - Retention: 7일 (분석용)
- [ ] **performance-metrics** (P0): 실시간 집계 결과
  - Partitions: 6, Replication: 3
  - Retention: 30일 (리포트용)
- [ ] **budget-management** (P1): 예산 동기화 및 캠페인 제어
  - Partitions: 3, Replication: 3
  - Retention: 7일
- [ ] **quality-score-updates** (P2): 품질 점수 업데이트
  - Partitions: 3, Replication: 3
  - Retention: 14일

**🔧 Consumer 설정**
- [ ] `enable.auto.commit`: false (수동 커밋)
- [ ] `isolation.level`: read_committed
- [ ] `max.poll.records`: 1000
- [ ] `fetch.min.bytes`: 1MB

---

### ✅ 10. 모니터링 및 알림

**🔧 메트릭 수집**
- [ ] **처리량**: 초당 처리 이벤트 수
- [ ] **지연시간**: 이벤트 처리 지연 시간
- [ ] **백프레셔**: 스트림 처리 병목 지점 감지
- [ ] **체크포인트**: 체크포인트 성공/실패율
- [ ] **예산 동기화**: Redis-DB 간 정확도

**📝 알림 설정**
- [ ] **지연 임계치**: 평균 지연시간 > 5초
- [ ] **처리량 저하**: 처리량이 평소의 50% 이하
- [ ] **체크포인트 실패**: 연속 3회 체크포인트 실패
- [ ] **예산 동기화 오차**: 정확도 < 95%
- [ ] **백프레셔**: 5분 이상 지속되는 백프레셔

---

### ✅ 11. 데이터 품질 관리

**🔧 데이터 검증**
- [ ] **스키마 검증**: Avro/JSON 스키마 기반 데이터 검증
- [ ] **중복 제거**: 이벤트 ID 기반 중복 이벤트 제거
- [ ] **지연 데이터**: Watermark 기반 지연 데이터 처리
- [ ] **데이터 정합성**: 실시간 집계와 배치 집계 비교

**📝 품질 메트릭**
- [ ] **유효 이벤트 비율**: 전체 이벤트 중 유효한 이벤트 비율
- [ ] **중복 이벤트 비율**: 중복으로 감지된 이벤트 비율
- [ ] **지연 이벤트 비율**: Watermark 이후 도착한 이벤트 비율

---

## 🚀 배포 및 운영

### ✅ 12. 장애 복구 절차

**🔧 복구 시나리오**
- [ ] **Job 실패**: 자동 재시작 및 Savepoint 복구
- [ ] **클러스터 장애**: HA 설정을 통한 자동 페일오버
- [ ] **데이터 손실**: 체크포인트 기반 상태 복구
- [ ] **성능 저하**: 자동 스케일링 및 리소스 조정
- [ ] **예산 동기화 실패**: 수동 Redis 카운터 보정

**📝 복구 절차서**
- [ ] 장애 감지 → 자동 알림 → 자동 복구 시도 → 수동 개입 → 정상화 확인 