# CPC RTB 시스템 아키텍처

## 📋 시스템 개요

**최적화 목표**: Citrus Ad 수준의 응답 성능 + 내재화의 확장성
- **API 응답**: < 50ms 광고 요청 처리
- **처리량**: 기존 대비 5배 증가
- **정확성**: 정확한 잔액 차감 및 24시간 클릭-전환 매칭

RTB(Real-Time Bidding) 시스템을 4개의 주요 컴포넌트로 구성:
- **API 서버**: 광고 요청 처리, RTB 로직, 잔액 차감
- **Database/Redis**: 실시간 데이터 조회 및 캐싱
- **Kafka**: 이벤트 스트리밍, 비동기 처리
- **Flink/Worker**: 실시간 집계 및 배치 처리

---

## 🏗️ 전체 시스템 아키텍처

```mermaid
graph TB
    subgraph "사용자 Interface"
        User[사용자]
        Admin[어드민]
    end
    
    subgraph "API Layer"
        API[API 서버<br/>- RTB 로직<br/>- 잔액 차감<br/>- 이벤트 발행]
    end
    
    subgraph "Data Storage"
        DB[(Database<br/>- 캠페인 정보<br/>- 잔액/예산<br/>- 실시간 조회)]
        Redis[(Redis<br/>- CTR/CVR 캐시<br/>- 세션 정보<br/>- 잔액/예산 선차감)]
    end
    
    subgraph "Event Processing"
        Kafka[Kafka<br/>- 이벤트 스트리밍<br/>- 비동기 처리<br/>- 내구성/재처리 보장]
        Worker[Worker<br/>- 배치 처리<br/>- 리포트 생성<br/>- DB 원자적 차감<br/>- 실패 시 재처리 로직]
        Flink[Flink<br/>- 실시간 집계<br/>- CTR/CVR 계산<br/>- 24시간 매칭]
    end
    
    subgraph "Data Lake"
        S3[(S3<br/>- 원시 이벤트<br/>- 장기 보관)]
    end
    
    User --> API
    Admin --> API
    
    API <--> DB
    API <--> Redis
    API --> Kafka
    
    Kafka --> Flink
    Kafka --> Worker
    Kafka --> S3
    
    Flink --> Redis
    Flink --> DB
    Worker --> DB
```

---

## 🔄 핵심 데이터 플로우

### 1. 광고 요청 플로우 (실시간 처리)

```mermaid
sequenceDiagram
    participant U as 사용자
    participant API as API 서버
    participant R as Redis
    participant DB as Database
    
    U->>API: 광고 요청 (placement, category, searchterm, exp_key, exp_var)
    
    Note over API: RTB 로직 실행
    API->>DB: 캠페인 정보 조회 (필터링 포함)
    Note over DB: 검색어/카테고리별 매칭<br/>잔액>0, 승인상태, 일예산 체크
    DB->>API: 유효 캠페인 목록
    
    API->>R: 일예산 실시간 체크
    R->>API: 오늘 사용금액 (daily_spent)
    
    API->>R: CTR/CVR 데이터 조회
    R->>API: 실시간 성과 지표
    
    API->>API: S_α 점수 계산 + 정렬
    API->>API: 가격 산정 (Pricing 알고리즘)
    
    alt 가격 실험 적용
        API->>DB: 실험 매핑 테이블 조회
        DB->>API: 실험용 상품코드 매핑
        API->>API: 상품코드 변환 (exp_key, exp_var 기반)
    end
    
    API->>U: 광고 응답 (총 30-50ms)
```

### 2. 클릭 처리 플로우 (Flink 로직 집중 + 단일 통합 토픽)

```mermaid
sequenceDiagram
    participant U as 사용자
    participant API as API 서버
    participant K1 as Kafka<br/>(raw-clicks)
    participant F as Flink
    participant K2 as Kafka<br/>(ad-domain-events)
    participant W as Worker
    participant DB as Database
    participant R as Redis
    participant S as Slack

    U->>API: 광고 클릭
    Note over API: 1. 토픽 발행
    API->>K1: 클릭 이벤트 발행
    API->>U: 즉시 응답 (2-3ms)
    
    K1->>F: 클릭 이벤트 스트림 수신
    F->>F: 전체 비즈니스 로직 실행
    Note over F: 2. Flink 스트림 처리 로직<br/><br/>📋 중복 제거<br/>- 1분 윈도우 내 동일 사용자+광고 필터링<br/>- 봇 트래픽 및 악의적 클릭 차단<br/><br/>💰 잔액 체크<br/>- 캠페인별 실시간 잔액 확인<br/>- 일예산/월예산 한도 검증<br/>- 클릭 단가 대비 충분성 판단<br/><br/>💲 단가 계산<br/>- 기본 입찰가 기반 동적 가격 산정<br/>- 실시간 경쟁 상황 반영<br/>- 사용자 프로필별 가격 조정<br/><br/>📊 성과 집계<br/>- 5분 윈도우 CTR/CVR 실시간 계산<br/>- 캠페인별 ROI 및 CPA 지표 산출<br/>- 품질 점수 업데이트<br/><br/>🎛️ 캠페인 제어<br/>- 잔액 부족 시 자동 중단 판단<br/>- 성과 저하 시 최적화 트리거<br/>- 비정상 패턴 감지 시 보호 모드

    F->>K2: Output 토픽 발행<br/>
    
    Note over W: 3. 후처리 작업
    K2->>W: Output 이벤트 컨슘
    W->>DB: 잔액, 로그, 캠페인 상태 업데이트
    W->>R: 실시간 캐시 데이터 업데이트
    W->>S: 캠페인 중단, 예산 부족 알람 발송
```

**처리 단계**:

1. **API 서버**: 클릭 이벤트를 Kafka 토픽에 발행 후 즉시 응답
2. **Flink**: 이벤트 스트림을 수집하여 모든 비즈니스 로직 실행 후 결과를 단일 Output 토픽에 발행
3. **Worker**: Output 토픽을 컨슘하여 DB/Redis 업데이트 및 Slack 알람 처리

### 3. 전환 처리 플로우

```mermaid
sequenceDiagram
    participant Order as 주문시스템
    participant API as API 서버
    participant K as Kafka
    participant F as Flink
    
    Order->>API: 구매 완료 이벤트
    API->>K: 전환 이벤트 발행
    
    Note over F: 24시간 윈도우 배치 처리
    K->>F: 이벤트 스트림 처리
    F->>F: 클릭-전환 매칭<br/>기여도 계산
    F->>DB: 결과 저장
```

### 4. 실시간 집계 플로우 (스트림 처리)

```mermaid
sequenceDiagram
    participant K as Kafka
    participant F as Flink
    participant R as Redis
    participant DB as Database
    
    K->>F: 노출/클릭/전환 이벤트 스트림
    
    Note over F: 실시간 윈도우 집계
    F->>F: CTR/CVR 계산 (5분 윈도우)
    F->>F: 방어값 통계 (1시간 윈도우)
    F->>F: 예산 소진 모니터링
    
    F->>R: 실시간 지표 업데이트
    Note over R: CTR/CVR 캐시 갱신<br/>방어값 통계 업데이트
    F->>DB: 집계 결과 저장
    
    Note over F: 예산 동기화 (10분마다)
    F->>DB: Redis 일예산 카운터 → DB 동기화
```

### 5. 검색어 광고 매칭 플로우

```mermaid
sequenceDiagram
    participant U as 사용자
    participant API as API 서버
    participant DB as Database
    
    U->>API: 검색 광고 요청 (placement=SEARCH, searchterm="노트북")
    
    Note over API: 검색어 기반 캠페인 필터링
    API->>DB: 검색어 매칭 캠페인 조회
    Note over DB: SELECT * FROM campaigns<br/>WHERE target_keywords LIKE '%노트북%'<br/>AND status='APPROVED'
    DB->>API: 매칭된 캠페인 목록
    
    Note over API: 일반 RTB 로직과 동일
    API->>API: S_α 점수 계산 + 정렬
    API->>U: 검색 광고 응답
```

### 6. 가격 실험 A/B 테스트 플로우 - 맞는지 확인 필요;;;

```mermaid
sequenceDiagram
    participant U as 사용자
    participant API as API 서버
    participant DB as Database
    participant K as Kafka
    
    U->>API: 실험 요청 (exp_key="mobile_ui", exp_var="B")
    
    Note over API: 일반 RTB 처리 완료 후
    API->>DB: 실험 매핑 조회
    Note over DB: SELECT experiment_product_id<br/>FROM experiment_mapping<br/>WHERE exp_key='mobile_ui' AND exp_var='B'
    DB->>API: 실험용 상품코드 매핑
    
    API->>API: 상품코드 변환
    Note over API: original_product → experiment_product
    API->>U: 실험 적용된 광고 응답
    
    Note over API: 실험 이벤트 로깅
    API->>K: 실험 추적 이벤트 발행
    Note over K: exp_key, exp_var 태깅된 이벤트
```

---

## 📊 컴포넌트별 역할 정의

### 🎯 API 서버
**주요 역할**:
- RTB 로직 실행 (S_α 점수 계산, 할당, 가격 산정)
- 잔액/예산 실시간 체크 및 차감
- 이벤트 발행 (Kafka)
- 어드민 인터페이스 제공

**성능 요구사항**:
- 광고 요청: < 50ms 응답
- 클릭 처리: < 20ms 응답
- 동시 처리: 1000 RPS

### 💾 Database
**저장 데이터**:
- 광고주, 캠페인, 상품 정보
- 잔액, 예산 정보 (실시간 업데이트)
- 집계된 성과 데이터
- 사용자 로그 (노출, 클릭, 전환)

**특징**:
- 트랜잭션 보장 (잔액 차감)
- 읽기 최적화 인덱싱

### ⚡ Redis
**캐시 데이터**:
- CTR/CVR 실시간 지표
- 세션 정보
- 방어값 통계

**TTL 설정**:
- CTR/CVR: 5분
- 방어값: 1시간
- 세션: 24시간

### 📡 Kafka
**토픽 구성**:
- `ad-events`: 노출, 클릭, 전환 이벤트
- `balance-updates`: 잔액 변경 이벤트
- `performance-metrics`: 성과 지표 업데이트

**특징**:
- 이벤트 순서 보장 (파티션별)
- 내구성 보장 (replication)

### 🔄 Flink
**처리 로직**:
- 실시간 CTR/CVR 계산 (5분 윈도우)
- 24시간 클릭-전환 매칭
- 방어값 통계 계산 (1시간 윈도우)
- 예산 소진 모니터링

**출력**:
- Redis 캐시 업데이트
- Database 집계 테이블 업데이트

### 🔧 Worker
**배치 작업**:
- 일별/월별 성과 리포트 생성
- 데이터 정합성 검증
- 장기 데이터 S3 이관
- 시스템 헬스체크

---

## ⚡ 성능 최적화 전략

### 1. 3레벨 조회 최적화

```mermaid
graph LR
    Request[API 요청] --> L1[L1: 메모리 캐시<br/>Application Level<br/>1초 TTL]
    L1 --> L2[L2: Redis<br/>5분 TTL<br/>분산 캐시]
    L2 --> L3[L3: Database<br/>실시간 데이터<br/>인덱스 최적화]
    
    L1 -.-> Response1[< 1ms]
    L2 -.-> Response2[< 5ms]  
    L3 -.-> Response3[< 20ms]
```

### 2. 데이터베이스 최적화

**파티셔닝**:
- 로그 테이블: 날짜별 파티셔닝
- 성과 테이블: 월별 파티셔닝

## 2. 🚨 **CDC 동시성 문제 - 맞습니다!**

**문제 시나리오**: